# LM Studio ì›ê²© ì„œë²„ êµ¬ì¶• ê°€ì´ë“œ

## ğŸ¯ ì˜µì…˜ 1: ì§‘ì— ìˆëŠ” ë‹¤ë¥¸ ì»´í“¨í„° í™œìš©

### í•„ìš” ì¡°ê±´
- **GPU**: RTX 3060 ì´ìƒ (6GB VRAM) ë˜ëŠ” M1/M2 Mac
- **RAM**: 8GB ì´ìƒ (16GB ê¶Œì¥)
- **ë„¤íŠ¸ì›Œí¬**: ê³ ì • IP ë˜ëŠ” DDNS

### ì„¤ì • ë°©ë²•

#### 1. ì›ê²© ì»´í“¨í„°ì— LM Studio ì„¤ì¹˜
```bash
# Windows/Macì—ì„œ LM Studio ë‹¤ìš´ë¡œë“œ
# https://lmstudio.ai

# ë˜ëŠ” Dockerë¡œ ì„¤ì¹˜ (Linux)
docker run -it --gpus all -p 1234:1234 \
  -v ./models:/app/models \
  lmstudio/server:latest
```

#### 2. ì™¸ë¶€ ì ‘ê·¼ í—ˆìš© ì„¤ì •
```bash
# LM Studio ì„¤ì •ì—ì„œ:
# - Server â†’ Enable CORS: âœ…
# - Server â†’ Allow Remote Connections: âœ…
# - Listen Address: 0.0.0.0:1234

# ë°©í™”ë²½ í¬íŠ¸ ê°œë°©
sudo ufw allow 1234  # Linux
# Windows: ë°©í™”ë²½ì—ì„œ 1234 í¬íŠ¸ í—ˆìš©
```

#### 3. í¬íŠ¸í¬ì›Œë”© ì„¤ì • (ê³µìœ ê¸°)
```
ì™¸ë¶€í¬íŠ¸: 1234 â†’ ë‚´ë¶€IP:1234
ì˜ˆ: 192.168.1.100:1234
```

#### 4. DDNS ì„¤ì • (ì„ íƒì‚¬í•­)
```bash
# ì§‘ IPê°€ ë°”ë€ŒëŠ” ê²½ìš°
# No-IP, DuckDNS ë“±ìœ¼ë¡œ ë„ë©”ì¸ ì—°ê²°
# ì˜ˆ: your-ai-server.ddns.net:1234
```

## ğŸš€ ì˜µì…˜ 2: í´ë¼ìš°ë“œ ì„œë²„ êµ¬ì¶• (ì¶”ì²œ)

### A. AWS EC2 GPU ì¸ìŠ¤í„´ìŠ¤
```bash
# g4dn.xlarge ì¸ìŠ¤í„´ìŠ¤ (Tesla T4)
# ì›” ë¹„ìš©: ~$300-400
# ì„±ëŠ¥: Gemma-2-3B ì¾Œì  ì‹¤í–‰

# ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸
#!/bin/bash
sudo apt update
sudo apt install -y docker.io nvidia-docker2

# LM Studio Server ì‹¤í–‰
docker run -d --gpus all --name lm-studio \
  -p 1234:1234 \
  -v /home/ubuntu/models:/app/models \
  --restart unless-stopped \
  lmstudio/server:latest
```

### B. Google Cloud Platform (ë” ì €ë ´)
```bash
# T4 GPU ì¸ìŠ¤í„´ìŠ¤
# ì›” ë¹„ìš©: ~$200-300
# Preemptible ì‚¬ìš©ì‹œ 70% í• ì¸

gcloud compute instances create ai-server \
  --zone=us-central1-a \
  --machine-type=n1-standard-4 \
  --accelerator=type=nvidia-tesla-t4,count=1 \
  --image-family=pytorch-latest-gpu \
  --image-project=deeplearning-platform-release
```

### C. Paperspace Gradient (ê°€ì¥ ì‰¬ì›€)
```bash
# ì›” $39ë¶€í„° GPU ì¸ìŠ¤í„´ìŠ¤
# LM Studio í”„ë¦¬ì„¤ì¹˜ ì´ë¯¸ì§€ ì œê³µ
# 1í´ë¦­ ë°°í¬ ê°€ëŠ¥
```

## ğŸ  ì˜µì…˜ 3: ë¯¸ë‹ˆPC ì „ìš© ì„œë²„ êµ¬ì¶•

### ì¶”ì²œ í•˜ë“œì›¨ì–´
```
1. Intel NUC 13 Pro + RTX 4060
   - ê°€ê²©: ~$1,500
   - ì „ë ¥: 150W
   - ì„±ëŠ¥: Gemma-2-3B ì™„ë²½ ì‹¤í–‰

2. Mac Mini M2 Pro
   - ê°€ê²©: ~$1,800
   - ì „ë ¥: 20W (ë§¤ìš° íš¨ìœ¨ì )
   - ì„±ëŠ¥: 16GB í†µí•©ë©”ëª¨ë¦¬ë¡œ ì¾Œì 

3. ì¤‘ê³  ì›Œí¬ìŠ¤í…Œì´ì…˜
   - HP Z440 + RTX 3060
   - ê°€ê²©: ~$800
   - ì„±ëŠ¥: ì¶©ë¶„
```

### 24/7 ìš´ì˜ ì„¤ì •
```bash
# systemd ì„œë¹„ìŠ¤ ë“±ë¡ (Linux)
sudo tee /etc/systemd/system/lm-studio.service << EOF
[Unit]
Description=LM Studio Server
After=network.target

[Service]
Type=simple
User=ubuntu
WorkingDirectory=/home/ubuntu
ExecStart=/usr/bin/docker run --gpus all -p 1234:1234 lmstudio/server
Restart=always

[Install]
WantedBy=multi-user.target
EOF

sudo systemctl enable lm-studio
sudo systemctl start lm-studio
```

## ğŸ“Š ë¹„ìš© ë¹„êµ

| ë°©ì‹ | ì´ˆê¸°ë¹„ìš© | ì›” ìš´ì˜ë¹„ | ì¥ì  | ë‹¨ì  |
|------|----------|-----------|------|------|
| ì§‘ ì»´í“¨í„° | $0 | ~$30 (ì „ê¸°) | ë¬´ë£Œ, ì™„ì „ í†µì œ | ì¸í„°ë„· ì˜ì¡´, ê´€ë¦¬ |
| ë¯¸ë‹ˆPC ì„œë²„ | $800-1,800 | ~$50 | ì €ì „ë ¥, ì•ˆì •ì  | ì´ˆê¸° íˆ¬ì |
| AWS GPU | $0 | $300-400 | í™•ì¥ì„±, ì•ˆì •ì„± | ë¹„ìŒˆ |
| GCP GPU | $0 | $200-300 | AWSë³´ë‹¤ ì €ë ´ | ë³µì¡í•¨ |
| Paperspace | $0 | $39-99 | ë§¤ìš° ì‰¬ì›€ | ì œí•œì  |

## âš¡ ìµœì í™” íŒ

### 1. ëª¨ë¸ ê²½ëŸ‰í™”
```python
# GGUF ì–‘ìí™”ë¡œ ë©”ëª¨ë¦¬ 50% ì ˆì•½
# Q4_K_M: í’ˆì§ˆ ìœ ì§€í•˜ë©´ì„œ ê²½ëŸ‰í™”
# Q8_0: ìµœê³  í’ˆì§ˆ, ì¡°ê¸ˆ ë¬´ê±°ì›€

# LM Studioì—ì„œ ìë™ ë‹¤ìš´ë¡œë“œ
"google/gemma-2-3b-it-GGUF/gemma-2-3b-it-q4_k_m.gguf"
```

### 2. ë¡œë“œë°¸ëŸ°ì‹±
```bash
# ì—¬ëŸ¬ ì„œë²„ ìš´ì˜ì‹œ
# nginxë¡œ ë¡œë“œë°¸ëŸ°ì‹±
upstream lm_studio {
    server 192.168.1.100:1234;
    server your-cloud-server:1234 backup;
}
```

### 3. ëª¨ë‹ˆí„°ë§
```bash
# ì„œë²„ ìƒíƒœ ì²´í¬
#!/bin/bash
while true; do
    if ! curl -f http://your-server:1234/v1/models; then
        echo "LM Studio down! Restarting..."
        docker restart lm-studio
    fi
    sleep 60
done
```